# ğŸ“‹ **FLOW Xá»¬ LÃ UPLOAD FILES**

> **MÃ´ táº£**: API upload vÃ  xá»­ lÃ½ multiple Excel files theo logic notebook vá»›i complete workflow tá»« raw data Ä‘áº¿n clean data vÃ  error handling.

---

## ğŸš€ **Phase 1: INITIALIZATION & SETUP**

### **1.1 Request Reception**

```http
POST: /data-processing/upload-files
Content-Type: multipart/form-data
Files: List[UploadFile] (Excel files .xlsx/.xls)
```

### **1.2 Service Initialization**

```python
processor = ExcelBatchProcessor(db)
results = {
    "processed_files": 0,     # Sá»‘ file Ä‘Ã£ xá»­ lÃ½ thÃ nh cÃ´ng
    "total_rows": 0,          # Tá»•ng sá»‘ rows Ä‘Ã£ insert
    "skipped_files": 0,       # Sá»‘ file Ä‘Ã£ import trÆ°á»›c Ä‘Ã³
    "errors": [],             # Danh sÃ¡ch lá»—i
    "file_details": [],       # Chi tiáº¿t tá»«ng file
    "processing_summary": {}, # Thá»‘ng kÃª sau khi process
}
```

### **1.3 Temporary Directory Setup**

```python
with tempfile.TemporaryDirectory() as temp_dir:
    # Táº¡o thÆ° má»¥c táº¡m Ä‘á»ƒ lÆ°u uploaded files
    # Auto cleanup khi exit
```

---

## ğŸ“‚ **Phase 2: FILE PROCESSING LOOP**

### **2.1 File Validation & Save**

#### **Validation Logic:**

```python
for file in files:
    # âœ… Kiá»ƒm tra extension
    if not file.filename.lower().endswith((".xlsx", ".xls")):
        results["errors"].append(f"File {file.filename} khÃ´ng pháº£i lÃ  Excel file")
        continue
```

#### **File Save:**

```python
# ğŸ’¾ Save file to temp directory
file_path = os.path.join(temp_dir, file.filename)
with open(file_path, "wb") as buffer:
    content = await file.read()
    buffer.write(content)
```

### **2.2 Duplicate Check**

```python
# ğŸ” Check import log table
if processor.is_file_imported(file.filename):
    print(f"â­ï¸ File {file.filename} Ä‘Ã£ Ä‘Æ°á»£c import trÆ°á»›c Ä‘Ã³")
    results["skipped_files"] += 1
    continue
```

**SQL Query:**

```sql
SELECT 1 FROM import_log WHERE file_name = :file_name
```

### **2.3 File Type Classification**

#### **Classification Logic (theo notebook):**

```python
file_type = processor.find_matching_key(file.filename)
```

| **File Type** | **Äiá»u kiá»‡n** | **MÃ´ táº£** |
|---------------|---------------|-----------|
| **MN** (Miá»n Nam) | Chá»©a chuá»—i `"toan cang"` | Files tá»« miá»n Nam |
| **MB** (Miá»n Báº¯c) | Báº¯t Ä‘áº§u vá»›i `"NAA"` | Files tá»« miá»n Báº¯c |
| **MT** (Miá»n Trung) | Báº¯t Ä‘áº§u vá»›i `"CV1"` | Files tá»« miá»n Trung |

---

## ğŸ“Š **Phase 3: EXCEL DATA EXTRACTION**

### **3.1 Excel File Processing**

```python
df = processor.process_excel_file(file_path, file.filename)
```

### **3.2 Read Excel Sheets**

```python
excel_sheets = pd.read_excel(file_path, sheet_name=None)
# Äá»c táº¥t cáº£ sheets trong file Excel
```

### **3.3 Process theo File Type**

#### **ğŸ”¸ MN (Miá»n Nam) Processing:**

```python
for sheet_name, df_sheet in excel_sheets.items():
    if len(sheet_name) >= 1:  # Process táº¥t cáº£ sheets
        # Lowercase column names
        df_sheet.columns = df_sheet.columns.str.lower()
        
        # Add metadata
        df_sheet['source'] = file_name
        df_sheet['sheet_name'] = sheet_name  # Sá»­ dá»¥ng sheet name gá»‘c
        
        # Data processing...
```

#### **ğŸ”¸ MB (Miá»n Báº¯c) Processing:**

```python
for sheet_name, df_sheet in excel_sheets.items():
    # Special logic: sheet_name tá»« route column
    df_sheet['sheet_name'] = df_sheet['route'].apply(
        lambda x: mb_sheet(x, search_list)
    )
    # mb_sheet() tÃ¬m airport codes trong route:
    # ["THD", "HPH", "HAN", "VDO", "VDH", "VII", "DIN"]
```

#### **ğŸ”¸ MT (Miá»n Trung) Processing:**

```python
for sheet_name, df_sheet in excel_sheets.items():
    df_sheet['sheet_name'] = sheet_name  # Sá»­ dá»¥ng sheet name gá»‘c
```

### **3.4 Column Processing**

#### **Ensure Required Columns:**

```python
columns_to_extract = [
    'flightdate', 'flightno', 'actype', 'route',
    'cgo', 'mail', 'seat', 'adl', 'chd', 'totalpax',
    'acregno', 'source', 'sheet_name'
]

# Add missing columns vá»›i NaN
for col in columns_to_extract:
    if col not in df_sheet.columns:
        df_sheet[col] = pd.NA
```

#### **Data Type Handling:**

```python
# Handle specific data types
df_sheet['flightdate'] = df_sheet['flightdate'].ffill()  # Forward fill
df_sheet['flightno'] = df_sheet['flightno'].fillna('').astype(str)
df_sheet['actype'] = df_sheet['actype'].fillna('').astype(str)
df_sheet['route'] = df_sheet['route'].fillna('').astype(str)
```

#### **Numeric Conversion:**

```python
numeric_columns = ['cgo', 'mail', 'adl', 'chd', 'seat', 'totalpax']

for col in numeric_columns:
    # Custom conversion function
    df_sheet[col] = df_sheet[col].apply(convert_to_float)
    df_sheet[col] = df_sheet[col].fillna(0)
```

**`convert_to_float()` Function:**

```python
def convert_to_float(value):
    try:
        if isinstance(value, str):
            value = value.replace(",", ".")  # Handle European decimal format
        return float(value) if pd.notnull(value) else 0.0
    except (ValueError, TypeError):
        return 0.0
```

### **3.5 Final Data Extraction**

```python
# Extract only required columns
extracted_df = df_sheet[columns_to_extract].copy()
combined_data.append(extracted_df)

# Combine all sheets
final_df = pd.concat(combined_data, ignore_index=True)
return final_df
```

---

## ğŸ’¾ **Phase 4: DATABASE OPERATIONS**

### **4.1 Save to flight_raw Table**

```python
processor._save_to_database(df)
```

#### **Database Insert Logic:**

```python
# Convert DataFrame to SQL
df.to_sql(
    'flight_raw', 
    con=self.db.bind, 
    if_exists='append', 
    index=False,
    dtype={
        col: UnicodeText 
        for col in df.select_dtypes(include=['object']).columns
    }
)
```

#### **SQL Structure:**

```sql
INSERT INTO flight_raw (
    flightdate, flightno, route, actype, seat, adl, chd, 
    cgo, mail, totalpax, source, acregno, sheet_name, 
    int_dom, created_at
) VALUES (
    '2024-01-15', 'VN123', 'SGN-HAN', 'A321', 180, 150, 10,
    2.5, 0.8, 160, 'file1.xlsx', 'VN-A123', 'SGN', NULL, SYSDATETIME()
)
```

### **4.2 Mark File as Imported**

```python
processor.mark_file_imported(file.filename, file_type, row_count)
```

#### **Import Log Entry:**

```sql
INSERT INTO import_log (file_name, source_type, row_count, import_date)
VALUES ('filename.xlsx', 'MN', 1500, SYSDATETIME())
```

### **4.3 Update Processing Results**

```python
results["processed_files"] += 1
results["total_rows"] += row_count
results["file_details"].append({
    "file_name": file.filename,
    "file_type": file_type,  # MN/MB/MT
    "rows": row_count,
})

print(f"âœ… ÄÃ£ lÆ°u {row_count} báº£n ghi tá»« file {file.filename}")
```

---

## ğŸ§¹ **Phase 5: DATA CLEANING & PROCESSING**

### **5.1 Commit Raw Data**

```python
db.commit()
print(f"ğŸ’¾ ÄÃ£ commit {results['total_rows']} báº£n ghi raw data")
```

### **5.2 Run Stored Procedures** *(náº¿u cÃ³ files Ä‘Æ°á»£c processed)*

#### **Step 5.2.1: usp_CleanAndProcessFlightData**

```python
print("1ï¸âƒ£ Cháº¡y stored procedure: usp_CleanAndProcessFlightData")
processor.run_data_cleaning_stored_procedure()
```

**Stored Procedure Tasks:**

| **Step** | **Action** | **Description** |
|----------|------------|-----------------|
| 1 | **Prepare Raw Data** | Update `totalpax = adl + chd` trong `flight_raw` |
| 2 | **Load to Staging** | Insert tá»« `flight_raw` â†’ `flight_clean_data_stg` |
| 3 | **Date Validation** | Validate vÃ  format `flightdate` |
| 4 | **Business Validation** | Check passengers, cargo, routes, actypes |
| 5 | **Load to Main** | Insert clean data â†’ `flight_data_chot` |
| 6 | **Error Handling** | Move invalid data â†’ `error_table` |
| 7 | **Missing Dimensions** | Log missing actypes/routes â†’ `Missing_Dimensions_Log` |

#### **Step 5.2.2: usp_CleanAndValidateFlightData**

```python
print("2ï¸âƒ£ Cháº¡y stored procedure: usp_CleanAndValidateFlightData")
from sqlalchemy import text
db.execute(text("EXEC usp_CleanAndValidateFlightData"))
db.commit()
```

**Validation Tasks:**

- **Re-validate error data**: Check láº¡i data trong `error_table`
- **Move valid data back**: Chuyá»ƒn valid records tá»« `error_table` â†’ `flight_data_chot`
- **Update error flags**: Cáº­p nháº­t validation flags

### **5.3 Get Processing Summary**

```python
results["processing_summary"] = processor.get_processing_summary()
```

#### **Summary Queries:**

```sql
-- Raw records count
SELECT COUNT(*) FROM flight_raw

-- Processed records count  
SELECT COUNT(*) FROM flight_data_chot

-- Error records count
SELECT COUNT(*) FROM error_table

-- Missing actypes count
SELECT COUNT(*) FROM Missing_Dimensions_Log WHERE Type = 'ACTYPE'

-- Missing routes count
SELECT COUNT(*) FROM Missing_Dimensions_Log WHERE Type = 'ROUTE'

-- Imported files count
SELECT COUNT(DISTINCT file_name) FROM import_log
```

---

## ğŸ“¤ **Phase 6: RESPONSE PREPARATION**

### **6.1 Success Message Construction**

```python
success_message = f"ÄÃ£ xá»­ lÃ½ thÃ nh cÃ´ng {results['processed_files']} file vá»›i tá»•ng {results['total_rows']} báº£n ghi"

if results["skipped_files"] > 0:
    success_message += f" (bá» qua {results['skipped_files']} file Ä‘Ã£ import)"

print(f"ğŸ‰ {success_message}")
```

### **6.2 Final API Response**

```json
{
    "success": true,
    "message": "ÄÃ£ xá»­ lÃ½ thÃ nh cÃ´ng 3 file vá»›i tá»•ng 1500 báº£n ghi (bá» qua 1 file Ä‘Ã£ import)",
    "processed_files": 3,
    "total_rows": 1500,
    "skipped_files": 1,
    "errors": [],
    "file_details": [
        {
            "file_name": "MN_toan_cang_data.xlsx",
            "file_type": "MN", 
            "rows": 500
        },
        {
            "file_name": "NAA_flight_data.xlsx",
            "file_type": "MB",
            "rows": 600
        },
        {
            "file_name": "CV1_central_data.xlsx", 
            "file_type": "MT",
            "rows": 400
        }
    ],
    "processing_summary": {
        "raw_records": 1500,
        "processed_records": 1400,
        "error_records": 100,
        "missing_actypes": 5,
        "missing_routes": 3,
        "imported_files": 4
    }
}
```

---

## ğŸš¨ **Error Handling & Edge Cases**

### **Global Error Handling**

```python
try:
    # ... entire workflow ...
except Exception as e:
    db.rollback()  # Rollback táº¥t cáº£ database changes
    error_msg = f"Lá»—i upload files: {str(e)}"
    print(f"ğŸ’¥ {error_msg}")
    logging.error(error_msg)
    raise HTTPException(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, 
        detail=error_msg
    )
```

### **File-level Error Scenarios**

| **Scenario** | **Action** | **Impact** |
|--------------|------------|------------|
| **Non-Excel File** | Add to `errors`, continue | KhÃ´ng dá»«ng process |
| **File Ä‘Ã£ Import** | TÄƒng `skipped_files`, continue | KhÃ´ng re-process |
| **Unknown File Type** | Add to `errors`, continue | File khÃ´ng Ä‘Æ°á»£c xá»­ lÃ½ |
| **Excel Read Error** | Add to `errors`, continue | File bá»‹ corrupt/format sai |
| **Database Error** | Add to `errors`, continue | Lá»—i constraint/data |
| **Stored Procedure Error** | Add to `errors`, return success | KhÃ´ng fail toÃ n bá»™ |

### **Error Response Example**

```json
{
    "success": true,
    "message": "ÄÃ£ xá»­ lÃ½ thÃ nh cÃ´ng 2 file vá»›i tá»•ng 1000 báº£n ghi",
    "processed_files": 2,
    "total_rows": 1000,
    "skipped_files": 1,
    "errors": [
        "File report.pdf khÃ´ng pháº£i lÃ  Excel file",
        "KhÃ´ng thá»ƒ xÃ¡c Ä‘á»‹nh loáº¡i file: unknown_format.xlsx",
        "Lá»—i xá»­ lÃ½ file corrupted.xlsx: File khÃ´ng Ä‘á»c Ä‘Æ°á»£c",
        "Lá»—i stored procedure: Missing foreign key constraint"
    ],
    "file_details": [...],
    "processing_summary": {...}
}
```

---

## ğŸ”— **Database Tables Flow**

### **Data Flow Diagram**

```
ğŸ“¤ Upload Files
    â†“
ğŸ“Š Excel Processing  
    â†“
ğŸ—„ï¸ flight_raw (Raw data storage)
    â†“
ğŸ“ import_log (File tracking)
    â†“
ğŸ§¹ usp_CleanAndProcessFlightData
    â†“
ğŸ—‚ï¸ flight_clean_data_stg (Staging)
    â†“
âœ… flight_data_chot (Clean data) 
âŒ error_table (Invalid data)
âš ï¸ Missing_Dimensions_Log (Missing refs)
    â†“
ğŸ”„ usp_CleanAndValidateFlightData
    â†“
ğŸ“Š Processing Summary
```

### **Tables Involved**

| **Table** | **Purpose** | **Usage** |
|-----------|-------------|-----------|
| `flight_raw` | Raw Excel data storage | Insert phase |
| `import_log` | File import tracking | Duplicate prevention |
| `flight_clean_data_stg` | Staging for validation | Temp processing |
| `flight_data_chot` | Main clean data table | Final validated data |
| `error_table` | Invalid data storage | Error records |
| `Missing_Dimensions_Log` | Missing references log | Data quality tracking |

---

## âš¡ **Performance Considerations**

### **Optimizations Implemented**

- âœ… **Batch Processing**: Multiple files trong single transaction
- âœ… **Temp Directory**: Auto cleanup Ä‘á»ƒ trÃ¡nh disk space issues  
- âœ… **Duplicate Prevention**: Check `import_log` trÆ°á»›c khi process
- âœ… **Error Isolation**: Lá»—i 1 file khÃ´ng áº£nh hÆ°á»Ÿng files khÃ¡c
- âœ… **Transaction Management**: Commit theo phases Ä‘á»ƒ trÃ¡nh long locks
- âœ… **Pandas Optimization**: `to_sql()` vá»›i proper dtypes

### **Scalability Notes**

- **Memory**: Large Excel files cÃ³ thá»ƒ consume significant memory
- **Transaction Size**: Very large batches cÃ³ thá»ƒ cause timeout
- **Disk Space**: Temp files cáº§n sufficient disk space
- **Database Locks**: Long-running transactions cÃ³ thá»ƒ block other operations

---

## ğŸ¯ **Success Criteria**

### **Complete Success**

- âœ… Táº¥t cáº£ files processed successfully
- âœ… KhÃ´ng cÃ³ errors
- âœ… Processing summary cÃ³ data Ä‘áº§y Ä‘á»§
- âœ… Stored procedures cháº¡y thÃ nh cÃ´ng

### **Partial Success**

- âœ… Má»™t sá»‘ files processed successfully
- âš ï¸ CÃ³ errors nhÆ°ng khÃ´ng critical
- âœ… Processing summary reflective of actual data
- âš ï¸ Stored procedures cÃ³ thá»ƒ cÃ³ warnings

### **Failure Scenarios**

- âŒ Database connection issues
- âŒ Permissions problems
- âŒ Disk space insufficient
- âŒ Critical stored procedure failures

---

## ğŸ“š **Related Endpoints**

### **Follow-up Actions**

- **`/export-missing-dimensions`**: Táº¡o Excel file cho missing data
- **`/import-missing-dimensions`**: Import data Ä‘Ã£ bá»• sung
- **`/revalidate-error-data`**: Re-process error records
- **`/processing-summary`**: Get latest processing stats
- **`/complete-workflow`**: Full workflow vá»›i missing data handling

### **Monitoring & Management**

- **`/stats`**: Overall system statistics
- **`/flight-data`**: Query processed flight data
- **`/missing-dimensions`**: List missing references
- **`/clear-flight-data`**: Reset data (development only)

---

*TÃ i liá»‡u nÃ y mÃ´ táº£ complete flow cá»§a API `/upload-files` theo implementation thá»±c táº¿ vÃ  logic tá»« notebook MSSQL_Airline.ipynb.*
