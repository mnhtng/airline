# üìã **FLOW X·ª¨ L√ù UPLOAD FILES**

> **M√¥ t·∫£**: API upload v√† x·ª≠ l√Ω multiple Excel files theo logic notebook v·ªõi complete workflow t·ª´ raw data ƒë·∫øn clean data v√† error handling.

---

## üöÄ **Phase 1: INITIALIZATION & SETUP**

### **1.1 Request Reception**

```http
POST: /data-processing/upload-files
Content-Type: multipart/form-data
Files: List[UploadFile] (Excel files .xlsx/.xls)
```

### **1.2 Service Initialization**

```python
processor = ExcelBatchProcessor(db)
results = {
    "processed_files": 0,     # S·ªë file ƒë√£ x·ª≠ l√Ω th√†nh c√¥ng
    "total_rows": 0,          # T·ªïng s·ªë rows ƒë√£ insert
    "skipped_files": 0,       # S·ªë file ƒë√£ import tr∆∞·ªõc ƒë√≥
    "errors": [],             # Danh s√°ch l·ªói
    "file_details": [],       # Chi ti·∫øt t·ª´ng file
    "processing_summary": {}, # Th·ªëng k√™ sau khi process
}
```

### **1.3 Temporary Directory Setup**

```python
with tempfile.TemporaryDirectory() as temp_dir:
    # T·∫°o th∆∞ m·ª•c t·∫°m ƒë·ªÉ l∆∞u uploaded files
    # Auto cleanup khi exit
```

---

## üìÇ **Phase 2: FILE PROCESSING LOOP**

### **2.1 File Validation & Save**

#### **Validation Logic:**

```python
for file in files:
    # ‚úÖ Ki·ªÉm tra extension
    if not file.filename.lower().endswith((".xlsx", ".xls")):
        results["errors"].append(f"File {file.filename} kh√¥ng ph·∫£i l√† Excel file")
        continue
```

#### **File Save:**

```python
# üíæ Save file to temp directory
file_path = os.path.join(temp_dir, file.filename)
with open(file_path, "wb") as buffer:
    content = await file.read()
    buffer.write(content)
```

### **2.2 Duplicate Check**

```python
# üîç Check import log table
if processor.is_file_imported(file.filename):
    print(f"‚è≠Ô∏è File {file.filename} ƒë√£ ƒë∆∞·ª£c import tr∆∞·ªõc ƒë√≥")
    results["skipped_files"] += 1
    continue
```

**SQL Query:**

```sql
SELECT 1 FROM import_log WHERE file_name = :file_name
```

### **2.3 File Type Classification**

#### **Classification Logic (theo notebook):**

```python
file_type = processor.find_matching_key(file.filename)
```

| **File Type** | **ƒêi·ªÅu ki·ªán** | **M√¥ t·∫£** |
|---------------|---------------|-----------|
| **MN** (Mi·ªÅn Nam) | Ch·ª©a chu·ªói `"toan cang"` | Files t·ª´ mi·ªÅn Nam |
| **MB** (Mi·ªÅn B·∫Øc) | B·∫Øt ƒë·∫ßu v·ªõi `"NAA"` | Files t·ª´ mi·ªÅn B·∫Øc |
| **MT** (Mi·ªÅn Trung) | B·∫Øt ƒë·∫ßu v·ªõi `"CV1"` | Files t·ª´ mi·ªÅn Trung |

---

## üìä **Phase 3: EXCEL DATA EXTRACTION**

### **3.1 Excel File Processing**

```python
df = processor.process_excel_file(file_path, file.filename)
```

### **3.2 Read Excel Sheets**

```python
excel_sheets = pd.read_excel(file_path, sheet_name=None)
# ƒê·ªçc t·∫•t c·∫£ sheets trong file Excel
```

### **3.3 Process theo File Type**

#### **üî∏ MN (Mi·ªÅn Nam) Processing:**

```python
for sheet_name, df_sheet in excel_sheets.items():
    if len(sheet_name) >= 1:  # Process t·∫•t c·∫£ sheets
        # Lowercase column names
        df_sheet.columns = df_sheet.columns.str.lower()
        
        # Add metadata
        df_sheet['source'] = file_name
        df_sheet['sheet_name'] = sheet_name  # S·ª≠ d·ª•ng sheet name g·ªëc
        
        # Data processing...
```

#### **üî∏ MB (Mi·ªÅn B·∫Øc) Processing:**

```python
for sheet_name, df_sheet in excel_sheets.items():
    # Special logic: sheet_name t·ª´ route column
    df_sheet['sheet_name'] = df_sheet['route'].apply(
        lambda x: mb_sheet(x, search_list)
    )
    # mb_sheet() t√¨m airport codes trong route:
    # ["THD", "HPH", "HAN", "VDO", "VDH", "VII", "DIN"]
```

#### **üî∏ MT (Mi·ªÅn Trung) Processing:**

```python
for sheet_name, df_sheet in excel_sheets.items():
    df_sheet['sheet_name'] = sheet_name  # S·ª≠ d·ª•ng sheet name g·ªëc
```

### **3.4 Column Processing**

#### **Ensure Required Columns:**

```python
columns_to_extract = [
    'flightdate', 'flightno', 'actype', 'route',
    'cgo', 'mail', 'seat', 'adl', 'chd', 'totalpax',
    'acregno', 'source', 'sheet_name'
]

# Add missing columns v·ªõi NaN
for col in columns_to_extract:
    if col not in df_sheet.columns:
        df_sheet[col] = pd.NA
```

#### **Data Type Handling:**

```python
# Handle specific data types
df_sheet['flightdate'] = df_sheet['flightdate'].ffill()  # Forward fill
df_sheet['flightno'] = df_sheet['flightno'].fillna('').astype(str)
df_sheet['actype'] = df_sheet['actype'].fillna('').astype(str)
df_sheet['route'] = df_sheet['route'].fillna('').astype(str)
```

#### **Numeric Conversion:**

```python
numeric_columns = ['cgo', 'mail', 'adl', 'chd', 'seat', 'totalpax']

for col in numeric_columns:
    # Custom conversion function
    df_sheet[col] = df_sheet[col].apply(convert_to_float)
    df_sheet[col] = df_sheet[col].fillna(0)
```

**`convert_to_float()` Function:**

```python
def convert_to_float(value):
    try:
        if isinstance(value, str):
            value = value.replace(",", ".")  # Handle European decimal format
        return float(value) if pd.notnull(value) else 0.0
    except (ValueError, TypeError):
        return 0.0
```

### **3.5 Final Data Extraction**

```python
# Extract only required columns
extracted_df = df_sheet[columns_to_extract].copy()
combined_data.append(extracted_df)

# Combine all sheets
final_df = pd.concat(combined_data, ignore_index=True)
return final_df
```

---

## üíæ **Phase 4: DATABASE OPERATIONS**

### **4.1 Save to flight_raw Table**

```python
processor._save_to_database(df)
```

#### **Database Insert Logic:**

```python
# Convert DataFrame to SQL
df.to_sql(
    'flight_raw', 
    con=self.db.bind, 
    if_exists='append', 
    index=False,
    dtype={
        col: UnicodeText 
        for col in df.select_dtypes(include=['object']).columns
    }
)
```

#### **SQL Structure:**

```sql
INSERT INTO flight_raw (
    flightdate, flightno, route, actype, seat, adl, chd, 
    cgo, mail, totalpax, source, acregno, sheet_name, 
    int_dom, created_at
) VALUES (
    '2024-01-15', 'VN123', 'SGN-HAN', 'A321', 180, 150, 10,
    2.5, 0.8, 160, 'file1.xlsx', 'VN-A123', 'SGN', NULL, SYSDATETIME()
)
```

### **4.2 Mark File as Imported**

```python
processor.mark_file_imported(file.filename, file_type, row_count)
```

#### **Import Log Entry:**

```sql
INSERT INTO import_log (file_name, source_type, row_count, import_date)
VALUES ('filename.xlsx', 'MN', 1500, SYSDATETIME())
```

### **4.3 Update Processing Results**

```python
results["processed_files"] += 1
results["total_rows"] += row_count
results["file_details"].append({
    "file_name": file.filename,
    "file_type": file_type,  # MN/MB/MT
    "rows": row_count,
})

print(f"‚úÖ ƒê√£ l∆∞u {row_count} b·∫£n ghi t·ª´ file {file.filename}")
```

---

## üßπ **Phase 5: DATA CLEANING & PROCESSING**

### **5.1 Commit Raw Data**

```python
db.commit()
print(f"üíæ ƒê√£ commit {results['total_rows']} b·∫£n ghi raw data")
```

### **5.2 Run Stored Procedures** *(n·∫øu c√≥ files ƒë∆∞·ª£c processed)*

#### **Step 5.2.1: usp_CleanAndProcessFlightData**

```python
print("1Ô∏è‚É£ Ch·∫°y stored procedure: usp_CleanAndProcessFlightData")
processor.run_data_cleaning_stored_procedure()
```

**Stored Procedure Tasks:**

| **Step** | **Action** | **Description** |
|----------|------------|-----------------|
| 1 | **Prepare Raw Data** | Update `totalpax = adl + chd` trong `flight_raw` |
| 2 | **Load to Staging** | Insert t·ª´ `flight_raw` ‚Üí `flight_clean_data_stg` |
| 3 | **Date Validation** | Validate v√† format `flightdate` |
| 4 | **Business Validation** | Check passengers, cargo, routes, actypes |
| 5 | **Load to Main** | Insert clean data ‚Üí `flight_data_chot` |
| 6 | **Error Handling** | Move invalid data ‚Üí `error_table` |
| 7 | **Missing Dimensions** | Log missing actypes/routes ‚Üí `Missing_Dimensions_Log` |

#### **Step 5.2.2: usp_CleanAndValidateFlightData**

```python
print("2Ô∏è‚É£ Ch·∫°y stored procedure: usp_CleanAndValidateFlightData")
from sqlalchemy import text
db.execute(text("EXEC usp_CleanAndValidateFlightData"))
db.commit()
```

**Validation Tasks:**

- **Re-validate error data**: Check l·∫°i data trong `error_table`
- **Move valid data back**: Chuy·ªÉn valid records t·ª´ `error_table` ‚Üí `flight_data_chot`
- **Update error flags**: C·∫≠p nh·∫≠t validation flags

### **5.3 Get Processing Summary**

```python
results["processing_summary"] = processor.get_processing_summary()
```

#### **Summary Queries:**

```sql
-- Raw records count
SELECT COUNT(*) FROM flight_raw

-- Processed records count  
SELECT COUNT(*) FROM flight_data_chot

-- Error records count
SELECT COUNT(*) FROM error_table

-- Missing actypes count
SELECT COUNT(*) FROM Missing_Dimensions_Log WHERE Type = 'ACTYPE'

-- Missing routes count
SELECT COUNT(*) FROM Missing_Dimensions_Log WHERE Type = 'ROUTE'

-- Imported files count
SELECT COUNT(DISTINCT file_name) FROM import_log
```

---

## üì§ **Phase 6: RESPONSE PREPARATION**

### **6.1 Success Message Construction**

```python
success_message = f"ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng {results['processed_files']} file v·ªõi t·ªïng {results['total_rows']} b·∫£n ghi"

if results["skipped_files"] > 0:
    success_message += f" (b·ªè qua {results['skipped_files']} file ƒë√£ import)"

print(f"üéâ {success_message}")
```

### **6.2 Final API Response**

```json
{
    "success": true,
    "message": "ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng 3 file v·ªõi t·ªïng 1500 b·∫£n ghi (b·ªè qua 1 file ƒë√£ import)",
    "processed_files": 3,
    "total_rows": 1500,
    "skipped_files": 1,
    "errors": [],
    "file_details": [
        {
            "file_name": "MN_toan_cang_data.xlsx",
            "file_type": "MN", 
            "rows": 500
        },
        {
            "file_name": "NAA_flight_data.xlsx",
            "file_type": "MB",
            "rows": 600
        },
        {
            "file_name": "CV1_central_data.xlsx", 
            "file_type": "MT",
            "rows": 400
        }
    ],
    "processing_summary": {
        "raw_records": 1500,
        "processed_records": 1400,
        "error_records": 100,
        "missing_actypes": 5,
        "missing_routes": 3,
        "imported_files": 4
    }
}
```

---

## üö® **Error Handling & Edge Cases**

### **Global Error Handling**

```python
try:
    # ... entire workflow ...
except Exception as e:
    db.rollback()  # Rollback t·∫•t c·∫£ database changes
    error_msg = f"L·ªói upload files: {str(e)}"
    print(f"üí• {error_msg}")
    logging.error(error_msg)
    raise HTTPException(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, 
        detail=error_msg
    )
```

### **File-level Error Scenarios**

| **Scenario** | **Action** | **Impact** |
|--------------|------------|------------|
| **Non-Excel File** | Add to `errors`, continue | Kh√¥ng d·ª´ng process |
| **File ƒë√£ Import** | TƒÉng `skipped_files`, continue | Kh√¥ng re-process |
| **Unknown File Type** | Add to `errors`, continue | File kh√¥ng ƒë∆∞·ª£c x·ª≠ l√Ω |
| **Excel Read Error** | Add to `errors`, continue | File b·ªã corrupt/format sai |
| **Database Error** | Add to `errors`, continue | L·ªói constraint/data |
| **Stored Procedure Error** | Add to `errors`, return success | Kh√¥ng fail to√†n b·ªô |

### **Error Response Example**

```json
{
    "success": true,
    "message": "ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng 2 file v·ªõi t·ªïng 1000 b·∫£n ghi",
    "processed_files": 2,
    "total_rows": 1000,
    "skipped_files": 1,
    "errors": [
        "File report.pdf kh√¥ng ph·∫£i l√† Excel file",
        "Kh√¥ng th·ªÉ x√°c ƒë·ªãnh lo·∫°i file: unknown_format.xlsx",
        "L·ªói x·ª≠ l√Ω file corrupted.xlsx: File kh√¥ng ƒë·ªçc ƒë∆∞·ª£c",
        "L·ªói stored procedure: Missing foreign key constraint"
    ],
    "file_details": [...],
    "processing_summary": {...}
}
```

---

## üîó **Database Tables Flow**

### **Data Flow Diagram**

```
üì§ Upload Files
    ‚Üì
üìä Excel Processing  
    ‚Üì
üóÑÔ∏è flight_raw (Raw data storage)
    ‚Üì
üìù import_log (File tracking)
    ‚Üì
üßπ usp_CleanAndProcessFlightData
    ‚Üì
üóÇÔ∏è flight_clean_data_stg (Staging)
    ‚Üì
‚úÖ flight_data_chot (Clean data) 
‚ùå error_table (Invalid data)
‚ö†Ô∏è Missing_Dimensions_Log (Missing refs)
    ‚Üì
üîÑ usp_CleanAndValidateFlightData
    ‚Üì
üìä Processing Summary
```

### **Tables Involved**

| **Table** | **Purpose** | **Usage** |
|-----------|-------------|-----------|
| `flight_raw` | Raw Excel data storage | Insert phase |
| `import_log` | File import tracking | Duplicate prevention |
| `flight_clean_data_stg` | Staging for validation | Temp processing |
| `flight_data_chot` | Main clean data table | Final validated data |
| `error_table` | Invalid data storage | Error records |
| `Missing_Dimensions_Log` | Missing references log | Data quality tracking |

---

## ‚ö° **Performance Considerations**

### **Optimizations Implemented**

- ‚úÖ **Batch Processing**: Multiple files trong single transaction
- ‚úÖ **Temp Directory**: Auto cleanup ƒë·ªÉ tr√°nh disk space issues  
- ‚úÖ **Duplicate Prevention**: Check `import_log` tr∆∞·ªõc khi process
- ‚úÖ **Error Isolation**: L·ªói 1 file kh√¥ng ·∫£nh h∆∞·ªüng files kh√°c
- ‚úÖ **Transaction Management**: Commit theo phases ƒë·ªÉ tr√°nh long locks
- ‚úÖ **Pandas Optimization**: `to_sql()` v·ªõi proper dtypes

### **Scalability Notes**

- **Memory**: Large Excel files c√≥ th·ªÉ consume significant memory
- **Transaction Size**: Very large batches c√≥ th·ªÉ cause timeout
- **Disk Space**: Temp files c·∫ßn sufficient disk space
- **Database Locks**: Long-running transactions c√≥ th·ªÉ block other operations

---

## üéØ **Success Criteria**

### **Complete Success**

- ‚úÖ T·∫•t c·∫£ files processed successfully
- ‚úÖ Kh√¥ng c√≥ errors
- ‚úÖ Processing summary c√≥ data ƒë·∫ßy ƒë·ªß
- ‚úÖ Stored procedures ch·∫°y th√†nh c√¥ng

### **Partial Success**

- ‚úÖ M·ªôt s·ªë files processed successfully
- ‚ö†Ô∏è C√≥ errors nh∆∞ng kh√¥ng critical
- ‚úÖ Processing summary reflective of actual data
- ‚ö†Ô∏è Stored procedures c√≥ th·ªÉ c√≥ warnings

### **Failure Scenarios**

- ‚ùå Database connection issues
- ‚ùå Permissions problems
- ‚ùå Disk space insufficient
- ‚ùå Critical stored procedure failures

---

## üìö **Related Endpoints**

### **Follow-up Actions**

- **`/export-missing-dimensions`**: T·∫°o Excel file cho missing data
- **`/import-missing-dimensions`**: Import data ƒë√£ b·ªï sung
- **`/revalidate-error-data`**: Re-process error records
- **`/processing-summary`**: Get latest processing stats
- **`/complete-workflow`**: Full workflow v·ªõi missing data handling

### **Monitoring & Management**

- **`/stats`**: Overall system statistics
- **`/flight-data`**: Query processed flight data
- **`/missing-dimensions`**: List missing references
- **`/clear-flight-data`**: Reset data (development only)

---

*T√†i li·ªáu n√†y m√¥ t·∫£ complete flow c·ªßa API `/upload-files` theo implementation th·ª±c t·∫ø v√† logic t·ª´ notebook MSSQL_Airline.ipynb.*
