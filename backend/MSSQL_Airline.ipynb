{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07c8b16f",
      "metadata": {
        "id": "07c8b16f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.13.7' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: '\"c:/Program Files/Python313/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "import os\n",
        "import pyodbc\n",
        "import shutil\n",
        "from sqlalchemy import create_engine, text\n",
        "from sqlalchemy.types import UnicodeText\n",
        "\n",
        "# --NƠI VIẾT CÁC HÀM--\n",
        "\n",
        "# Xác định loại file Excel (MN: miền nam, MB: miền bắc, MT: miền trung)\n",
        "def find_matching_key(json_data, text):\n",
        "    text_lower = text.lower().strip()\n",
        "\n",
        "    for key, values in json_data.items():\n",
        "        for value in values:\n",
        "            value_lower = value.lower().strip()\n",
        "\n",
        "            if key == \"MN\":\n",
        "                if value_lower in text_lower:\n",
        "                    return key\n",
        "            else:  # MB, MT\n",
        "                if text_lower.startswith(value_lower):\n",
        "                    return key\n",
        "\n",
        "    return None\n",
        "\n",
        "# Chuyển text thành số thực\n",
        "def convert_to_float(value):\n",
        "    try:\n",
        "        # Convert ',' to '.' if present\n",
        "        if isinstance(value, str):\n",
        "            value = value.replace(',', '.')\n",
        "\n",
        "        # Convert to float, return 0 if not possible\n",
        "        return float(value) if pd.notnull(value) else 0.0\n",
        "    except (ValueError, TypeError):\n",
        "        return 0.0\n",
        "\n",
        "# Chuyên xử lý MB\n",
        "def mb_sheet(text, search_list):\n",
        "    \"\"\"\n",
        "    Tìm giá trị đầu tiên trong search_list có chứa trong text\n",
        "\n",
        "    Args:\n",
        "        text (str): Chuỗi cần kiểm tra\n",
        "        search_list (list): Danh sách các giá trị cần tìm\n",
        "\n",
        "    Returns:\n",
        "        str or None: Giá trị đầu tiên tìm thấy hoặc None nếu không tìm thấy\n",
        "    \"\"\"\n",
        "    if pd.isna(text):  # Xử lý trường hợp NaN\n",
        "        return None\n",
        "\n",
        "    text_str = str(text).upper()\n",
        "\n",
        "    for value in search_list:\n",
        "        if str(value).upper() in text_str:\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "# Đọc + xử lý data từ file Excel\n",
        "def process_excel_files(file_name , data_folder , json_data , search_list):\n",
        "    combined_data = []\n",
        "    columns_to_extract = [\n",
        "        'flightdate', 'flightno', 'actype', 'route',\n",
        "        'cgo', 'mail',  'seat', 'adl', 'chd', 'totalpax',\n",
        "        'acregno', 'source', 'sheet_name'\n",
        "    ]\n",
        "    file_path =  data_folder\n",
        "\n",
        "    # Convert col sang chữ thường\n",
        "    columns_to_extract = [col.lower() for col in columns_to_extract]\n",
        "    numeric_columns = ['cgo', 'mail', 'adl', 'chd' , 'seat']\n",
        "\n",
        "    # Iterate through files in the directory\n",
        "        # Filter files containing 'update' and 'toan cang'\n",
        "    if find_matching_key ( json_data , file_name) == \"MN\":\n",
        "        full_file_path = os.path.join(file_path, file_name)\n",
        "\n",
        "        try:\n",
        "            # Read all sheets in the Excel file\n",
        "            excel_sheets = pd.read_excel(full_file_path, sheet_name=None)\n",
        "\n",
        "            # Loop each sheet\n",
        "            for sheet_name, df_sheet in excel_sheets.items():\n",
        "                # Process only sheets with 3-character names\n",
        "                if len(sheet_name) >= 1:\n",
        "                    # Lowercase column names\n",
        "                    df_sheet.columns = df_sheet.columns.str.lower()\n",
        "\n",
        "                    # Add missing columns with None/NaN\n",
        "                    for col in columns_to_extract:\n",
        "                        if col not in df_sheet.columns:\n",
        "                            df_sheet[col] = pd.NA\n",
        "\n",
        "                    # Add metadata columns\n",
        "                    df_sheet['source'] = file_name\n",
        "                    df_sheet['sheet_name'] = sheet_name\n",
        "\n",
        "                    # Handle specific column data types and fill missing values\n",
        "                    # ffill(): điền value thiếu (NaN/None) = value gần nhất phía trên nó\n",
        "                    # fillna(''): điền value thiếu (NaN/None) = chuỗi rỗng + astype(): ép kiểu\n",
        "                    df_sheet['flightdate'] = df_sheet['flightdate'].ffill()\n",
        "                    df_sheet['flightno'] = df_sheet['flightno'].fillna('').astype(str)\n",
        "                    df_sheet['actype'] = df_sheet['actype'].fillna('').astype(str)\n",
        "                    df_sheet['route'] = df_sheet['route'].fillna('').astype(str)\n",
        "\n",
        "                    # Convert numeric columns to float\n",
        "                    for col in numeric_columns:\n",
        "                        try:\n",
        "                            df_sheet[col] = df_sheet[col].apply(convert_to_float)\n",
        "\n",
        "                            # Fallback if couldn't convert NaN/None\n",
        "                            df_sheet[col] = df_sheet[col].fillna(0)\n",
        "                        except Exception as e:\n",
        "                            logging.error(f\"Error processing numeric column '{col}' in sheet '{sheet_name}' from file '{file_name}': {e}. Attempting to fill with 0.\")\n",
        "                            df_sheet[col] = df_sheet[col].fillna(0) # Fallback\n",
        "\n",
        "                    # Extract specified columns\n",
        "                    extracted_df = df_sheet[columns_to_extract].copy()\n",
        "                    combined_data.append(extracted_df)\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error processing file {file_name}: {e}\")\n",
        "\n",
        "    elif  find_matching_key ( json_data , file_name) == \"MT\" :\n",
        "            full_file_path = os.path.join(file_path, file_name)\n",
        "\n",
        "            try:\n",
        "                # Read all sheets in the Excel file\n",
        "                excel_sheets = pd.read_excel(full_file_path, sheet_name=None)\n",
        "\n",
        "                numeric_columns = ['cgo', 'mail', 'adl', 'chd' , 'totalpax','seat']\n",
        "                for sheet_name, df_sheet in excel_sheets.items():\n",
        "                    # Process only sheets with 3-character names\n",
        "                    if len(sheet_name) >= 1:\n",
        "                        # Lowercase column names\n",
        "                        df_sheet.columns = df_sheet.columns.str.lower()\n",
        "\n",
        "                        # Add missing columns with None/NaN\n",
        "                        for col in columns_to_extract:\n",
        "                            if col not in df_sheet.columns:\n",
        "                                df_sheet[col] = pd.NA\n",
        "\n",
        "                        # Add metadata columns\n",
        "                        df_sheet['source'] = file_name\n",
        "                        df_sheet['sheet_name'] = sheet_name\n",
        "\n",
        "                        # Handle specific column data types and fill missing values\n",
        "                        df_sheet['flightdate'] = df_sheet['flightdate'].ffill()\n",
        "                        df_sheet['flightno'] = df_sheet['flightno'].fillna('').astype(str)\n",
        "                        df_sheet['actype'] = df_sheet['actype'].fillna('').astype(str)\n",
        "                        df_sheet['route'] = df_sheet['route'].fillna('').astype(str)\n",
        "\n",
        "                        # Convert numeric columns using custom conversion function\n",
        "                        for col in numeric_columns:\n",
        "                            df_sheet[col] = df_sheet[col].apply(convert_to_float)\n",
        "\n",
        "                        # Extract specified columns\n",
        "                        extracted_df = df_sheet[columns_to_extract].copy()\n",
        "                        combined_data.append(extracted_df)\n",
        "\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error processing file {file_name}: {e}\")\n",
        "\n",
        "    elif  find_matching_key ( json_data , file_name) == \"MB\" :\n",
        "            full_file_path = os.path.join(file_path, file_name)\n",
        "\n",
        "            try:\n",
        "                # Read all sheets in the Excel file\n",
        "                print ( \"MB: file \" + file_name )\n",
        "                excel_sheets = pd.read_excel(full_file_path, sheet_name=None)\n",
        "\n",
        "                numeric_columns = ['cgo', 'mail', 'adl', 'chd' , 'seat' , 'totalpax']\n",
        "                for sheet_name, df_sheet in excel_sheets.items():\n",
        "                    # Process only sheets with 3-character names\n",
        "                    if len(sheet_name) >= 1:\n",
        "                        # Lowercase column names\n",
        "                        df_sheet.columns = df_sheet.columns.str.lower()\n",
        "\n",
        "                        # Add missing columns with None/NaN\n",
        "                        for col in columns_to_extract:\n",
        "                            if col not in df_sheet.columns:\n",
        "                                df_sheet[col] = pd.NA\n",
        "\n",
        "                        # Add metadata columns\n",
        "                        df_sheet['source'] = file_name\n",
        "                        # Handle specific column data types and fill missing values\n",
        "                        df_sheet['flightdate'] = df_sheet['flightdate'].ffill()\n",
        "                        df_sheet['flightno'] = df_sheet['flightno'].fillna('').astype(str)\n",
        "                        df_sheet['actype'] = df_sheet['actype'].fillna('').astype(str)\n",
        "                        df_sheet['route'] = df_sheet['route'].fillna('').astype(str)\n",
        "                        df_sheet['sheet_name'] = df_sheet['route'].apply( lambda x: mb_sheet(x, search_list))\n",
        "\n",
        "                        # Convert numeric columns using custom conversion function\n",
        "                        for col in numeric_columns:\n",
        "                            df_sheet[col] = df_sheet[col].apply(convert_to_float)\n",
        "\n",
        "                        # Extract specified columns\n",
        "                        extracted_df = df_sheet[columns_to_extract].copy()\n",
        "                        combined_data.append(extracted_df)\n",
        "\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error processing file {file_name}: {e}\")\n",
        "\n",
        "    # Combine all DataFrames\n",
        "    else:\n",
        "        print( \"Error\")\n",
        "\n",
        "    if combined_data:\n",
        "        final_df = pd.concat(combined_data, ignore_index=True)\n",
        "        return final_df\n",
        "    else:\n",
        "        logging.warning(\"No data extracted from files.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def connect_to_sql_server(database , server):\n",
        "    try:\n",
        "        connection_string = (\n",
        "            f\"mssql+pyodbc://@{server}/{database}\"\n",
        "            \"?driver=ODBC+Driver+17+for+SQL+Server\"\n",
        "        )\n",
        "        engine = create_engine(connection_string)\n",
        "        print(\"Connected to SQL Server successfully!\")\n",
        "        return engine\n",
        "    except Exception as e:\n",
        "        print(f\"Error connecting to SQL Server: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Hàm kiểm tra file đã import chưa\n",
        "def is_file_imported(con , file_name):\n",
        "    if con :\n",
        "        # with engine.connect() as con:\n",
        "        query = text(\"SELECT 1 FROM import_log WHERE file_name = :file_name\")\n",
        "        result = con.execute(query, {\"file_name\": file_name}).fetchone()\n",
        "        return result is not None\n",
        "    return False\n",
        "\n",
        "# Hàm đánh dấu file đã import\n",
        "def mark_file_imported(con, file_name, source_type, row_count):\n",
        "    print('log row')\n",
        "    insert_query = text(\"\"\"\n",
        "        INSERT INTO import_log (file_name, source_type, row_count)\n",
        "        VALUES (:file_name, :source_type, :row_count)\n",
        "    \"\"\")\n",
        "    con.execute(insert_query, {\n",
        "        \"file_name\": file_name,\n",
        "        \"source_type\": source_type,\n",
        "        \"row_count\": row_count\n",
        "    })\n",
        "\n",
        "# Func điều phối việc import các file Excel\n",
        "def import_file (engine , data_folder , destination_folder , json_data , search_list, ):\n",
        "    if engine:\n",
        "        with engine.begin() as con:\n",
        "            for file in os.listdir(data_folder) :\n",
        "                if not is_file_imported(con, file):\n",
        "                    print(f\"Đang xử lý: {file}\")\n",
        "                    try:\n",
        "                        if  str(file).find('xl') > 0:\n",
        "                            df = process_excel_files(file , data_folder , json_data , search_list)\n",
        "                            print( len (df ))\n",
        "                            row_count = len(df)\n",
        "\n",
        "                            # Ghi data vào table 'flight_raw'\n",
        "                            df[df[\"flightno\"].notna() & df[\"actype\"].notna()][\n",
        "                                [\n",
        "                                    \"flightdate\",\n",
        "                                    \"flightno\",\n",
        "                                    \"route\",\n",
        "                                    \"actype\",\n",
        "                                    \"seat\",\n",
        "                                    \"adl\",\n",
        "                                    \"chd\",\n",
        "                                    \"cgo\",\n",
        "                                    \"mail\",\n",
        "                                    \"totalpax\",\n",
        "                                    \"source\",\n",
        "                                    \"acregno\",\n",
        "                                    \"sheet_name\",\n",
        "                                ]\n",
        "                            ].to_sql(\n",
        "                                \"flight_raw\",\n",
        "                                con=conn,\n",
        "                                if_exists=\"append\",\n",
        "                                index=False,\n",
        "                                dtype={\n",
        "                                    \"source\": UnicodeText(),\n",
        "                                    \"sheet_name\": UnicodeText(),\n",
        "                                    \"flightdate\": UnicodeText(),\n",
        "                                },\n",
        "                            )\n",
        "\n",
        "                            # Ghi lại thông tin import vào bảng import_log\n",
        "                            mark_file_imported(con, file, 'type1', row_count)\n",
        "\n",
        "                            # Di chuyển tệp đã xử lý từ data_folder sang destination_folder\n",
        "                            file_path = os.path.join(data_folder, file)\n",
        "                            shutil.move(file_path, os.path.join(destination_folder, file))\n",
        "\n",
        "                            print(f\"Đã import file: {file}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Lỗi khi xử lý file {file}: {e}\")\n",
        "                else:\n",
        "                    print(f\"{file} đã được import trước đó, bỏ qua.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32a00840",
      "metadata": {
        "id": "32a00840"
      },
      "source": [
        "## Chay dong dau truoc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95912d56",
      "metadata": {
        "id": "95912d56",
        "outputId": "af13b868-cea0-4ef3-a549-60db5a076be2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to SQL Server successfully!\n",
            "Đang xử lý: CV1 Số liệu toan cang tuan 28.2025.xlsx\n",
            "6336\n",
            "log row\n",
            "Đã import file: CV1 Số liệu toan cang tuan 28.2025.xlsx\n",
            "Đang xử lý: CV1 Số liệu toan cang tuan 29.2025.xlsx\n",
            "6409\n",
            "log row\n",
            "Đã import file: CV1 Số liệu toan cang tuan 29.2025.xlsx\n",
            "Đang xử lý: CV1 Số liệu toan cang tuan 30.2025.xlsx\n",
            "6422\n",
            "log row\n",
            "Đã import file: CV1 Số liệu toan cang tuan 30.2025.xlsx\n",
            "Đang xử lý: CV1 Số liệu toan cang tuan 31.2025.xlsx\n",
            "6284\n",
            "log row\n",
            "Đã import file: CV1 Số liệu toan cang tuan 31.2025.xlsx\n",
            "Đang xử lý: CV1 TUAN 28 2025.xlsx\n",
            "3898\n",
            "log row\n",
            "Đã import file: CV1 TUAN 28 2025.xlsx\n",
            "Đang xử lý: CV1 TUAN 29 2025.xlsx\n",
            "3879\n",
            "log row\n",
            "Đã import file: CV1 TUAN 29 2025.xlsx\n",
            "Đang xử lý: CV1 TUAN 30 2025.xlsx\n",
            "3861\n",
            "log row\n",
            "Đã import file: CV1 TUAN 30 2025.xlsx\n",
            "Đang xử lý: CV1 TUAN 31 2025.xlsx\n",
            "3720\n",
            "log row\n",
            "Đã import file: CV1 TUAN 31 2025.xlsx\n",
            "Đang xử lý: Final_import_2.ipynb\n",
            "Đang xử lý: NAA_CV1 Tuần 28.2025.xlsx\n",
            "MB: file NAA_CV1 Tuần 28.2025.xlsx\n",
            "5218\n",
            "log row\n",
            "Đã import file: NAA_CV1 Tuần 28.2025.xlsx\n",
            "Đang xử lý: NAA_CV1 Tuần 29.2025.xlsx\n",
            "MB: file NAA_CV1 Tuần 29.2025.xlsx\n",
            "5076\n",
            "log row\n",
            "Đã import file: NAA_CV1 Tuần 29.2025.xlsx\n",
            "Đang xử lý: NAA_CV1 Tuần 30.2025.xlsx\n",
            "MB: file NAA_CV1 Tuần 30.2025.xlsx\n",
            "5156\n",
            "log row\n",
            "Đã import file: NAA_CV1 Tuần 30.2025.xlsx\n",
            "Đang xử lý: NAA_CV1 Tuần 31.2025.xlsx\n",
            "MB: file NAA_CV1 Tuần 31.2025.xlsx\n",
            "5022\n",
            "log row\n",
            "Đã import file: NAA_CV1 Tuần 31.2025.xlsx\n"
          ]
        }
      ],
      "source": [
        "# --NƠI THỰC THI--\n",
        "\n",
        "json_data = {\n",
        "    \"MN\": [\"toan cang\"], # chua ten bien\n",
        "    \"MB\": [\"NAA\"], # bat dau\n",
        "    \"MT\": [\"CV1\"] # bat dau\n",
        "}\n",
        "\n",
        "# Ds các actype\n",
        "search_list =  [\n",
        "  \"THD\",\n",
        "  \"HPH\",\n",
        "  \"HAN\",\n",
        "  \"VDO\",\n",
        "  \"VDH\",\n",
        "  \"VII\",\n",
        "  \"DIN\"\n",
        "]\n",
        "\n",
        "# Kết nối SQL\n",
        "server = 'DESKTOP-MC6MTTM\\\\SQLEXPRESS'\n",
        "engine = connect_to_sql_server( database= 'flight' , server= server)\n",
        "\n",
        "\n",
        "# Đường dẫn đến folder chứa các file Excel cần xử lý\n",
        "data_folder = r\"D:\\Code Python\\Format_data\"\n",
        "\n",
        "# Đường dẫn đến folder để lưu trữ các file đã xử lý\n",
        "destination_folder = r\"D:\\Code Python\\imported_file\"\n",
        "\n",
        "import_file( engine= engine , data_folder= data_folder , destination_folder= destination_folder ,json_data= json_data, search_list = search_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05051f17",
      "metadata": {
        "id": "05051f17"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a2b7f891",
      "metadata": {
        "id": "a2b7f891"
      },
      "source": [
        "## Trả kết quả ra file thiếu route và actype chứa seat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab1fb94c",
      "metadata": {
        "id": "ab1fb94c",
        "outputId": "035e7dcf-ee0b-4750-b437-8c81fba60696"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to SQL Server successfully!\n"
          ]
        }
      ],
      "source": [
        "import pyodbc\n",
        "import os\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.types import UnicodeText\n",
        "from openpyxl import load_workbook\n",
        "# Kết nối tới SQL Server qua SQLAlchemy\n",
        "\n",
        "\n",
        "server = 'DESKTOP-MC6MTTM\\\\SQLEXPRESS'\n",
        "def connect_to_sql_server(database , server):\n",
        "    try:\n",
        "        connection_string = (\n",
        "            f\"mssql+pyodbc://@{server}/{database}\"\n",
        "            \"?driver=ODBC+Driver+17+for+SQL+Server\"\n",
        "        )\n",
        "        engine = create_engine(connection_string)\n",
        "        print(\"Connected to SQL Server successfully!\")\n",
        "        return engine\n",
        "    except Exception as e:\n",
        "        print(f\"Error connecting to SQL Server: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "con = connect_to_sql_server( server= server, database='flight')\n",
        "query1 = '''\n",
        "select top 0 *\n",
        "from actype_seat\n",
        "union all\n",
        "select Value , null\n",
        "from Missing_Dimensions_Log\n",
        "where type = 'Actype'\n",
        "group by Value\n",
        "'''\n",
        "\n",
        "query2 = '''\n",
        "select top 0\n",
        "    [ROUTE],\n",
        "    [AC],\n",
        "    [Route_ID],\n",
        "    [FLIGHT HOUR],\n",
        "    [TAXI],\n",
        "    [BLOCK HOUR],\n",
        "    [DISTANCE KM],\n",
        "    [Loại],\n",
        "    [Type],\n",
        "    [Country]\n",
        "from Route\n",
        "union\n",
        "select  Value ,NULL AS from_airport,\n",
        "    NULL AS to_airport,\n",
        "    NULL AS route_type,\n",
        "    NULL AS cgo,\n",
        "    NULL AS pax,\n",
        "    NULL AS mail,\n",
        "    NULL AS airline_code,\n",
        "    NULL AS note,\n",
        "    NULL AS created_by\n",
        "from Missing_Dimensions_Log\n",
        "where type = 'Route'\n",
        "and value is not null\n",
        "'''\n",
        "\n",
        "query3 = '''\n",
        "select top 0\n",
        "    [ROUTE],\n",
        "    [Distance mile GDS],\n",
        "    [Distance km GDS],\n",
        "    [Sector_2],\n",
        "    [Country 1],\n",
        "    [Country 2],\n",
        "    [Country],\n",
        "    [DOM/INT],\n",
        "    [Area]\n",
        "from Airline_Route_Details\n",
        "union\n",
        "select  Value ,\n",
        "\tNULL  ,\n",
        "    NULL ,\n",
        "    NULL ,\n",
        "    NULL,\n",
        "    NULL ,\n",
        "    NULL,\n",
        "    NULL ,\n",
        "    NULL\n",
        "from Missing_Dimensions_Log\n",
        "where type = 'Route'\n",
        "and value is not null\n",
        "'''\n",
        "\n",
        "# Đọc kết quả\n",
        "df1 = pd.read_sql(query1, con )\n",
        "df2 = pd.read_sql(query2, con )\n",
        "df3 = pd.read_sql(query3, con )\n",
        "\n",
        "\n",
        "with pd.ExcelWriter( r\"D:\\Code Python\\Add_information.xlsx\", engine='openpyxl' ) as writer:\n",
        "    df1.to_excel(writer, sheet_name='Actype_seat', index=False)\n",
        "    df2.to_excel(writer, sheet_name='Route', index=False)\n",
        "    df3.to_excel(writer, sheet_name='Airline_Route_Details', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22c276de",
      "metadata": {
        "id": "22c276de"
      },
      "source": [
        "## Thêm các giá trị còn thiếu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c16459e",
      "metadata": {
        "id": "8c16459e",
        "outputId": "e9eeecf0-c5f8-40a3-8388-4cfc2b932f54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to SQL Server successfully!\n"
          ]
        },
        {
          "ename": "InterfaceError",
          "evalue": "(pyodbc.InterfaceError) ('IM002', '[IM002] [Microsoft][ODBC Driver Manager] Data source name not found and no default driver specified (0) (SQLDriverConnect)')\n(Background on this error at: https://sqlalche.me/e/20/rvf5)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mInterfaceError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:146\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28mself\u001b[39m._dbapi_connection = \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m dialect.loaded_dbapi.Error \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:3298\u001b[39m, in \u001b[36mEngine.raw_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3277\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[32m   3278\u001b[39m \n\u001b[32m   3279\u001b[39m \u001b[33;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3296\u001b[39m \n\u001b[32m   3297\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3298\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:449\u001b[39m, in \u001b[36mPool.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[32m    443\u001b[39m \n\u001b[32m    444\u001b[39m \u001b[33;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    447\u001b[39m \n\u001b[32m    448\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:1263\u001b[39m, in \u001b[36m_ConnectionFairy._checkout\u001b[39m\u001b[34m(cls, pool, threadconns, fairy)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[32m-> \u001b[39m\u001b[32m1263\u001b[39m     fairy = \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1265\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:712\u001b[39m, in \u001b[36m_ConnectionRecord.checkout\u001b[39m\u001b[34m(cls, pool)\u001b[39m\n\u001b[32m    711\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m712\u001b[39m     rec = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\impl.py:179\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dec_overflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:146\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\impl.py:177\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:390\u001b[39m, in \u001b[36mPool._create_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:674\u001b[39m, in \u001b[36m_ConnectionRecord.__init__\u001b[39m\u001b[34m(self, pool, connect)\u001b[39m\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[32m--> \u001b[39m\u001b[32m674\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[38;5;28mself\u001b[39m.finalize_callback = deque()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:900\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m900\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mError on connect(): \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:146\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:896\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    895\u001b[39m \u001b[38;5;28mself\u001b[39m.starttime = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m896\u001b[39m \u001b[38;5;28mself\u001b[39m.dbapi_connection = connection = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    897\u001b[39m pool.logger.debug(\u001b[33m\"\u001b[39m\u001b[33mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, connection)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\create.py:646\u001b[39m, in \u001b[36mcreate_engine.<locals>.connect\u001b[39m\u001b[34m(connection_record)\u001b[39m\n\u001b[32m    644\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[32m--> \u001b[39m\u001b[32m646\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:622\u001b[39m, in \u001b[36mDefaultDialect.connect\u001b[39m\u001b[34m(self, *cargs, **cparams)\u001b[39m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, *cargs, **cparams):\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloaded_dbapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mInterfaceError\u001b[39m: ('IM002', '[IM002] [Microsoft][ODBC Driver Manager] Data source name not found and no default driver specified (0) (SQLDriverConnect)')",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mInterfaceError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m route.dropna()\n\u001b[32m      9\u001b[39m route_detail.dropna()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mactype\u001b[49m\u001b[43m[\u001b[49m\u001b[43mactype\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mseat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnotnull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTempActypeImport\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mappend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m route[route[\u001b[33m'\u001b[39m\u001b[33mCountry\u001b[39m\u001b[33m'\u001b[39m].notnull()].to_sql( \u001b[33m'\u001b[39m\u001b[33mTempRouteImport\u001b[39m\u001b[33m'\u001b[39m , if_exists=\u001b[33m\"\u001b[39m\u001b[33mappend\u001b[39m\u001b[33m\"\u001b[39m, con = engine , index = \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_stored_procedure\u001b[39m(engine, procedure_name):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:3087\u001b[39m, in \u001b[36mNDFrame.to_sql\u001b[39m\u001b[34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[39m\n\u001b[32m   2889\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2890\u001b[39m \u001b[33;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[32m   2891\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3083\u001b[39m \u001b[33;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[32m   3084\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m   3085\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[32m-> \u001b[39m\u001b[32m3087\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3088\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3089\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3090\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3091\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3092\u001b[39m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3093\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3094\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\sql.py:841\u001b[39m, in \u001b[36mto_sql\u001b[39m\u001b[34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[39m\n\u001b[32m    836\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame, DataFrame):\n\u001b[32m    837\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    838\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mframe\u001b[39m\u001b[33m'\u001b[39m\u001b[33m argument should be either a Series or a DataFrame\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    839\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpandasSQL_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_transaction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m    842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql.to_sql(\n\u001b[32m    843\u001b[39m         frame,\n\u001b[32m    844\u001b[39m         name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    853\u001b[39m         **engine_kwargs,\n\u001b[32m    854\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\sql.py:906\u001b[39m, in \u001b[36mpandasSQL_builder\u001b[39m\u001b[34m(con, schema, need_transaction)\u001b[39m\n\u001b[32m    903\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUsing URI string without sqlalchemy installed.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sqlalchemy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, (\u001b[38;5;28mstr\u001b[39m, sqlalchemy.engine.Connectable)):\n\u001b[32m--> \u001b[39m\u001b[32m906\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSQLDatabase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_transaction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    908\u001b[39m adbc = import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33madbc_driver_manager.dbapi\u001b[39m\u001b[33m\"\u001b[39m, errors=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    909\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m adbc \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, adbc.Connection):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\sql.py:1636\u001b[39m, in \u001b[36mSQLDatabase.__init__\u001b[39m\u001b[34m(self, con, schema, need_transaction)\u001b[39m\n\u001b[32m   1634\u001b[39m     \u001b[38;5;28mself\u001b[39m.exit_stack.callback(con.dispose)\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, Engine):\n\u001b[32m-> \u001b[39m\u001b[32m1636\u001b[39m     con = \u001b[38;5;28mself\u001b[39m.exit_stack.enter_context(\u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m need_transaction \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m con.in_transaction():\n\u001b[32m   1638\u001b[39m     \u001b[38;5;28mself\u001b[39m.exit_stack.enter_context(con.begin())\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:3274\u001b[39m, in \u001b[36mEngine.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3251\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Connection:\n\u001b[32m   3252\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[32m   3253\u001b[39m \n\u001b[32m   3254\u001b[39m \u001b[33;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3271\u001b[39m \n\u001b[32m   3272\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3274\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:148\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[39m\n\u001b[32m    146\u001b[39m         \u001b[38;5;28mself\u001b[39m._dbapi_connection = engine.raw_connection()\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect.loaded_dbapi.Error \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m         \u001b[43mConnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception_noconnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2439\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception_noconnection\u001b[39m\u001b[34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[39m\n\u001b[32m   2437\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[32m   2438\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2439\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001b[32m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2440\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2441\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:146\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m         \u001b[38;5;28mself\u001b[39m._dbapi_connection = \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect.loaded_dbapi.Error \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    148\u001b[39m         Connection._handle_dbapi_exception_noconnection(\n\u001b[32m    149\u001b[39m             err, dialect, engine\n\u001b[32m    150\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:3298\u001b[39m, in \u001b[36mEngine.raw_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3276\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> PoolProxiedConnection:\n\u001b[32m   3277\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[32m   3278\u001b[39m \n\u001b[32m   3279\u001b[39m \u001b[33;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3296\u001b[39m \n\u001b[32m   3297\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3298\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:449\u001b[39m, in \u001b[36mPool.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> PoolProxiedConnection:\n\u001b[32m    442\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[32m    443\u001b[39m \n\u001b[32m    444\u001b[39m \u001b[33;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    447\u001b[39m \n\u001b[32m    448\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:1263\u001b[39m, in \u001b[36m_ConnectionFairy._checkout\u001b[39m\u001b[34m(cls, pool, threadconns, fairy)\u001b[39m\n\u001b[32m   1255\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1256\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_checkout\u001b[39m(\n\u001b[32m   1257\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1260\u001b[39m     fairy: Optional[_ConnectionFairy] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1261\u001b[39m ) -> _ConnectionFairy:\n\u001b[32m   1262\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[32m-> \u001b[39m\u001b[32m1263\u001b[39m         fairy = \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1265\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1266\u001b[39m             threadconns.current = weakref.ref(fairy)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:712\u001b[39m, in \u001b[36m_ConnectionRecord.checkout\u001b[39m\u001b[34m(cls, pool)\u001b[39m\n\u001b[32m    710\u001b[39m     rec = cast(_ConnectionRecord, pool._do_get())\n\u001b[32m    711\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m712\u001b[39m     rec = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    715\u001b[39m     dbapi_connection = rec.get_connection()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\impl.py:179\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_connection()\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dec_overflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:146\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    148\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\impl.py:177\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inc_overflow():\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m util.safe_reraise():\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:390\u001b[39m, in \u001b[36mPool._create_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ConnectionPoolEntry:\n\u001b[32m    388\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:674\u001b[39m, in \u001b[36m_ConnectionRecord.__init__\u001b[39m\u001b[34m(self, pool, connect)\u001b[39m\n\u001b[32m    672\u001b[39m \u001b[38;5;28mself\u001b[39m.__pool = pool\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[32m--> \u001b[39m\u001b[32m674\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[38;5;28mself\u001b[39m.finalize_callback = deque()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:900\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    898\u001b[39m     \u001b[38;5;28mself\u001b[39m.fresh = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m900\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mError on connect(): \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    903\u001b[39m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[32m    904\u001b[39m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:146\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    148\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:896\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    894\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    895\u001b[39m     \u001b[38;5;28mself\u001b[39m.starttime = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m896\u001b[39m     \u001b[38;5;28mself\u001b[39m.dbapi_connection = connection = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    897\u001b[39m     pool.logger.debug(\u001b[33m\"\u001b[39m\u001b[33mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, connection)\n\u001b[32m    898\u001b[39m     \u001b[38;5;28mself\u001b[39m.fresh = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\create.py:646\u001b[39m, in \u001b[36mcreate_engine.<locals>.connect\u001b[39m\u001b[34m(connection_record)\u001b[39m\n\u001b[32m    643\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    644\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[32m--> \u001b[39m\u001b[32m646\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:622\u001b[39m, in \u001b[36mDefaultDialect.connect\u001b[39m\u001b[34m(self, *cargs, **cparams)\u001b[39m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, *cargs, **cparams):\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloaded_dbapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mInterfaceError\u001b[39m: (pyodbc.InterfaceError) ('IM002', '[IM002] [Microsoft][ODBC Driver Manager] Data source name not found and no default driver specified (0) (SQLDriverConnect)')\n(Background on this error at: https://sqlalche.me/e/20/rvf5)"
          ]
        }
      ],
      "source": [
        "from sqlalchemy import create_engine, text\n",
        "engine = connect_to_sql_server( con , 'flight')\n",
        "\n",
        "actype = pd.read_excel ( 'Add_information.xlsx', sheet_name=\"Actype_seat\")\n",
        "route= pd.read_excel ( 'Add_information.xlsx', sheet_name=\"Route\")\n",
        "# route_detail= pd.read_excel ( 'Add_information.xlsx', sheet_name=\"Route\")\n",
        "route_detail= pd.read_excel ( 'Add_information.xlsx', sheet_name=\"Airline_Route_Details\")\n",
        "\n",
        "# Drop các row chứa bất kỳ value thiếu (NaN/None)\n",
        "actype.dropna()\n",
        "route.dropna()\n",
        "route_detail.dropna()\n",
        "\n",
        "actype[actype['seat'].notnull()].to_sql( 'TempActypeImport' , if_exists=\"append\", con= engine , index = False)\n",
        "route[route['Country'].notnull()].to_sql( 'TempRouteImport' , if_exists=\"append\", con = engine , index = False)\n",
        "\n",
        "# Stored procedure sẽ lấy data từ các bảng tạm TempActypeImport và TempRouteImport để cập nhật/thêm mới data vào các bảng chính\n",
        "def execute_stored_procedure(engine, procedure_name):\n",
        "    \"\"\"\n",
        "    Execute stored procedure using SQLAlchemy 2.0 engine\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with engine.begin() as connection:  # auto-commit context\n",
        "            print(f\"Executing stored procedure {procedure_name}...\")\n",
        "            connection.execute(text(f\"EXEC {procedure_name}\"))\n",
        "            print(\"Stored procedure executed successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error executing stored procedure: {e}\")\n",
        "\n",
        "# Kết nối và thực thi\n",
        "if engine:\n",
        "    execute_stored_procedure(engine, 'dbo.usp_ImportAndUpdateMissingDimensions')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4216e8d1",
      "metadata": {
        "id": "4216e8d1",
        "outputId": "de55892a-525e-4fd4-fc46-c884a3d3f040"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ROUTE</th>\n",
              "      <th>AC</th>\n",
              "      <th>Route_ID</th>\n",
              "      <th>FH (THEO GIỜ)</th>\n",
              "      <th>FLIGHT HOUR</th>\n",
              "      <th>TAXI</th>\n",
              "      <th>BLOCK HOUR</th>\n",
              "      <th>DISTANCE KM</th>\n",
              "      <th>Loại</th>\n",
              "      <th>Type</th>\n",
              "      <th>Country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AKL-HAN</td>\n",
              "      <td>Wide_body</td>\n",
              "      <td>AKLHANWide_body</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>0.5</td>\n",
              "      <td>11.5</td>\n",
              "      <td>9200</td>\n",
              "      <td>INT</td>\n",
              "      <td>Long_haul</td>\n",
              "      <td>NZ-VN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     ROUTE         AC         Route_ID  FH (THEO GIỜ)  FLIGHT HOUR  TAXI  \\\n",
              "0  AKL-HAN  Wide_body  AKLHANWide_body             11           11   0.5   \n",
              "\n",
              "   BLOCK HOUR  DISTANCE KM Loại       Type Country  \n",
              "0        11.5         9200  INT  Long_haul   NZ-VN  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "actype = pd.read_excel ( 'output.xlsx', sheet_name=\"Actype\")\n",
        "route= pd.read_excel ( 'output.xlsx', sheet_name=\"Route\")\n",
        "actype.dropna()\n",
        "route.dropna()\n",
        "# actype[actype['seat'].notnull()]\n",
        "# .to_sql( 'TempActypeImport' , if_exists=\"append\", con= engine , index = False)\n",
        "route[route['Country'].notnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "995a694c",
      "metadata": {
        "id": "995a694c",
        "outputId": "40d64883-0553-4b69-9e05-b0dd32078add"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MB\n",
            "MT\n"
          ]
        }
      ],
      "source": [
        "type = find_matching_key (json_data , \"CV1 TUAN 51 2024.xlsx\")\n",
        "type2 = find_matching_key (json_data , \"NAA CV1 tuan 3 2025.xlsx\")\n",
        "print( type )\n",
        "print( type2 )\n",
        "# actype = pd.read_excel ( 'output.xlsx', sheet_name=\"Actype\")\n",
        "# route= pd.read_excel ( 'output.xlsx', sheet_name=\"Route\")\n",
        "# route"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
