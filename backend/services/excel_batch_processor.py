import pandas as pd
import logging
import os
import shutil
from typing import Dict, List, Any, Tuple, Optional
from sqlalchemy.orm import Session
from sqlalchemy import text
from sqlalchemy.types import UnicodeText
import re
import datetime
from pathlib import Path


class ExcelBatchProcessor:
    """
    X·ª≠ l√Ω batch import d·ªØ li·ªáu Excel

    Args:
        db (Session): Session c·ªßa database

    Returns:
        Dict[str, Any]: K·∫øt qu·∫£ x·ª≠ l√Ω
    """

    def __init__(self, db: Session):
        self.db = db

        # C·∫•u h√¨nh t·ª´ notebook
        self.json_data = {
            "MN": ["toan cang"],  # mi·ªÅn nam - ch·ª©a t√™n bi·∫øn
            "MB": ["NAA"],  # mi·ªÅn b·∫Øc - b·∫Øt ƒë·∫ßu
            "MT": ["CV1"],  # mi·ªÅn trung - b·∫Øt ƒë·∫ßu
        }

        # Danh s√°ch c√°c airport codes
        self.search_list = ["THD", "HPH", "HAN", "VDO", "VDH", "VII", "DIN"]

        # C√°c c·ªôt c·∫ßn extract
        self.columns_to_extract = [
            "flightdate",
            "flightno",
            "actype",
            "route",
            "cgo",
            "mail",
            "seat",
            "adl",
            "chd",
            "totalpax",
            "acregno",
            "source",
            "sheet_name",
        ]

        # C√°c c·ªôt ki·ªÉu s·ªë th·ª±c
        self.numeric_columns = ["cgo", "mail", "adl", "chd", "seat", "totalpax"]

    def find_matching_key(self, text: str) -> Optional[str]:
        """
        X√°c ƒë·ªãnh lo·∫°i file Excel (MN: mi·ªÅn nam, MB: mi·ªÅn b·∫Øc, MT: mi·ªÅn trung)

        Args:
            text (str): Chu·ªói c·∫ßn ki·ªÉm tra

        Returns:
            str or None: Lo·∫°i file t√¨m th·∫•y ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
        """

        text_lower = text.lower().strip()

        for key, values in self.json_data.items():
            for value in values:
                value_lower = value.lower().strip()

                if key == "MN":
                    if value_lower in text_lower:
                        return key
                else:  # MB, MT
                    if text_lower.startswith(value_lower):
                        return key

        return None

    def convert_to_float(self, value: Any) -> float:
        """
        Chuy·ªÉn text th√†nh s·ªë th·ª±c

        Args:
            value (Any): Gi√° tr·ªã c·∫ßn chuy·ªÉn ƒë·ªïi

        Returns:
            float: Gi√° tr·ªã s·ªë th·ª±c ho·∫∑c 0.0 n·∫øu kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi
        """

        try:
            # Convert ',' to '.' if present
            if isinstance(value, str):
                value = value.replace(",", ".")

            # Convert to float, return 0 if not possible
            return float(value) if pd.notnull(value) else 0.0
        except (ValueError, TypeError):
            return 0.0

    def mb_sheet(self, text: str) -> Optional[str]:
        """
        T√¨m gi√° tr·ªã ƒë·∫ßu ti√™n trong search_list c√≥ ch·ª©a trong text

        Args:
            text (str): Chu·ªói c·∫ßn ki·ªÉm tra
            search_list (list): Danh s√°ch c√°c gi√° tr·ªã c·∫ßn t√¨m

        Returns:
            str or None: Gi√° tr·ªã ƒë·∫ßu ti√™n t√¨m th·∫•y ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
        """

        if pd.isna(text):  # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p NaN
            return None

        text_str = str(text).upper()

        for value in self.search_list:
            if str(value).upper() in text_str:
                return value

        return None

    def process_excel_file(self, file_path: str, file_name: str) -> pd.DataFrame:
        """
        X·ª≠ l√Ω m·ªôt file Excel

        Args:
            file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel
            file_name (str): T√™n file Excel

        Returns:
            pd.DataFrame: DataFrame ch·ª©a d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω
        """

        combined_data = []

        try:
            # Determine file type
            file_type = self.find_matching_key(file_name)
            if not file_type:
                logging.error(f"Kh√¥ng th·ªÉ x√°c ƒë·ªãnh lo·∫°i file: {file_name}")
                return pd.DataFrame()

            if file_type == "MN":
                # Process MN (Mi·ªÅn Nam) files
                combined_data = self._process_mn_file(file_path, file_name)

            elif file_type == "MT":
                # Process MT (Mi·ªÅn Trung) files
                combined_data = self._process_mt_file(file_path, file_name)

            elif file_type == "MB":
                # Process MB (Mi·ªÅn B·∫Øc) files
                combined_data = self._process_mb_file(file_path, file_name)

            # Combine all DataFrames
            if combined_data:
                final_df = pd.concat(combined_data, ignore_index=True)
                return final_df
            else:
                logging.warning(
                    f"Kh√¥ng c√≥ d·ªØ li·ªáu ƒë∆∞·ª£c tr√≠ch xu·∫•t t·ª´ file: {file_name}"
                )
                return pd.DataFrame()

        except Exception as e:
            logging.error(f"L·ªói x·ª≠ l√Ω file {file_name}: {e}")
            return pd.DataFrame()

    def _process_mn_file(self, file_path: str, file_name: str) -> List[pd.DataFrame]:
        """
        X·ª≠ l√Ω file MN (Mi·ªÅn Nam)

        Args:
            file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel
            file_name (str): T√™n file Excel

        Returns:
            List[pd.DataFrame]: Danh s√°ch c√°c DataFrame ƒë√£ x·ª≠ l√Ω
        """

        combined_data = []

        try:
            # Read all sheets in the Excel file
            excel_sheets = pd.read_excel(file_path, sheet_name=None)

            # Loop through each sheet
            for sheet_name, df_sheet in excel_sheets.items():
                # Process only sheets with at least 1 character
                if len(sheet_name) >= 1:
                    processed_df = self._process_sheet_common(
                        df_sheet, file_name, sheet_name
                    )
                    if not processed_df.empty:
                        combined_data.append(processed_df)

        except Exception as e:
            logging.error(f"L·ªói x·ª≠ l√Ω file MN {file_name}: {e}")

        return combined_data

    def _process_mt_file(self, file_path: str, file_name: str) -> List[pd.DataFrame]:
        """
        X·ª≠ l√Ω file MT (Mi·ªÅn Trung)

        Args:
            file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel
            file_name (str): T√™n file Excel

        Returns:
            List[pd.DataFrame]: Danh s√°ch c√°c DataFrame ƒë√£ x·ª≠ l√Ω
        """

        combined_data = []

        try:
            # Read all sheets in the Excel file
            excel_sheets = pd.read_excel(file_path, sheet_name=None)

            for sheet_name, df_sheet in excel_sheets.items():
                # Process only sheets with at least 1 character
                if len(sheet_name) >= 1:
                    processed_df = self._process_sheet_common(
                        df_sheet, file_name, sheet_name
                    )
                    if not processed_df.empty:
                        combined_data.append(processed_df)

        except Exception as e:
            logging.error(f"L·ªói x·ª≠ l√Ω file MT {file_name}: {e}")

        return combined_data

    def _process_mb_file(self, file_path: str, file_name: str) -> List[pd.DataFrame]:
        """
        X·ª≠ l√Ω file MB (Mi·ªÅn B·∫Øc)

        Args:
            file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel
            file_name (str): T√™n file Excel

        Returns:
            List[pd.DataFrame]: Danh s√°ch c√°c DataFrame ƒë√£ x·ª≠ l√Ω
        """

        combined_data = []

        try:
            print(f"MB: file {file_name}")
            # Read all sheets in the Excel file
            excel_sheets = pd.read_excel(file_path, sheet_name=None)

            for sheet_name, df_sheet in excel_sheets.items():
                # Process only sheets with at least 1 character
                if len(sheet_name) >= 1:
                    # Lowercase column names
                    df_sheet.columns = df_sheet.columns.str.lower()

                    # Add missing columns with None/NaN
                    for col in self.columns_to_extract:
                        if col not in df_sheet.columns:
                            df_sheet[col] = pd.NA

                    # Add metadata columns
                    df_sheet["source"] = file_name

                    # Handle specific column data types and fill missing values
                    df_sheet["flightdate"] = df_sheet["flightdate"].ffill()
                    df_sheet["flightno"] = df_sheet["flightno"].fillna("").astype(str)
                    df_sheet["actype"] = df_sheet["actype"].fillna("").astype(str)
                    df_sheet["route"] = df_sheet["route"].fillna("").astype(str)

                    # For MB, sheet_name is derived from route
                    df_sheet["sheet_name"] = df_sheet["route"].apply(
                        lambda x: self.mb_sheet(x)
                    )

                    # Convert numeric columns using custom conversion function
                    for col in self.numeric_columns:
                        df_sheet[col] = df_sheet[col].apply(self.convert_to_float)

                    # Extract specified columns
                    extracted_df = df_sheet[self.columns_to_extract].copy()
                    combined_data.append(extracted_df)

        except Exception as e:
            logging.error(f"L·ªói x·ª≠ l√Ω file MB {file_name}: {e}")

        return combined_data

    def _process_sheet_common(
        self, df_sheet: pd.DataFrame, file_name: str, sheet_name: str
    ) -> pd.DataFrame:
        """
        X·ª≠ l√Ω chung cho c√°c sheet (MN, MT)

        Args:
            df_sheet (pd.DataFrame): DataFrame ch·ª©a d·ªØ li·ªáu c·ªßa sheet
            file_name (str): T√™n file Excel
            sheet_name (str): T√™n sheet

        Returns:
            pd.DataFrame: DataFrame ch·ª©a d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω
        """

        try:
            # Lowercase column names
            df_sheet.columns = df_sheet.columns.str.lower()

            # Add missing columns with None/NaN
            for col in self.columns_to_extract:
                if col not in df_sheet.columns:
                    df_sheet[col] = pd.NA

            # Add metadata columns
            df_sheet["source"] = file_name
            df_sheet["sheet_name"] = sheet_name

            # Handle specific column data types and fill missing values
            df_sheet["flightdate"] = df_sheet["flightdate"].ffill()
            df_sheet["flightno"] = df_sheet["flightno"].fillna("").astype(str)
            df_sheet["actype"] = df_sheet["actype"].fillna("").astype(str)
            df_sheet["route"] = df_sheet["route"].fillna("").astype(str)

            # Convert numeric columns using custom conversion function
            for col in self.numeric_columns:
                try:
                    df_sheet[col] = df_sheet[col].apply(self.convert_to_float)
                    df_sheet[col] = df_sheet[col].fillna(0)
                except Exception as e:
                    logging.error(
                        f"L·ªói x·ª≠ l√Ω c·ªôt s·ªë th·ª±c '{col}' trong sheet '{sheet_name}' t·ª´ file '{file_name}': {e}"
                    )
                    df_sheet[col] = df_sheet[col].fillna(0)

            # Extract specified columns
            extracted_df = df_sheet[self.columns_to_extract].copy()
            return extracted_df

        except Exception as e:
            logging.error(f"L·ªói x·ª≠ l√Ω sheet '{sheet_name}' t·ª´ file '{file_name}': {e}")
            return pd.DataFrame()

    def is_file_imported(self, file_name: str) -> bool:
        """
        Ki·ªÉm tra file ƒë√£ import ch∆∞a

        Args:
            file_name (str): T√™n file Excel

        Returns:
            bool: True n·∫øu file ƒë√£ import, False n·∫øu kh√¥ng
        """

        try:
            query = text("SELECT 1 FROM import_log WHERE file_name = :file_name")
            result = self.db.execute(query, {"file_name": file_name}).fetchone()
            return result is not None
        except Exception as e:
            logging.error(f"L·ªói ki·ªÉm tra file ƒë√£ import: {e}")
            return False

    def mark_file_imported(self, file_name: str, source_type: str, row_count: int):
        """
        ƒê√°nh d·∫•u file ƒë√£ import

        Args:
            file_name (str): T√™n file Excel
            source_type (str): Lo·∫°i source
            row_count (int): S·ªë l∆∞·ª£ng d√≤ng

        Returns:
            None
        """

        try:
            insert_query = text(
                """
                INSERT INTO import_log (file_name, source_type, row_count)
                VALUES (:file_name, :source_type, :row_count)
            """
            )
            self.db.execute(
                insert_query,
                {
                    "file_name": file_name,
                    "source_type": source_type,
                    "row_count": row_count,
                },
            )
            print(f"ƒê√£ ƒë√°nh d·∫•u file ƒë√£ import: {file_name}")
        except Exception as e:
            logging.error(f"L·ªói ƒë√°nh d·∫•u file ƒë√£ import: {e}")
            raise e

    def batch_import_files(
        self, data_folder: str, destination_folder: str
    ) -> Dict[str, Any]:
        """
        Import batch c√°c file Excel t·ª´ folder

        Args:
            data_folder (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn folder ch·ª©a c√°c file Excel
            destination_folder (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn folder ch·ª©a c√°c file Excel ƒë√£ import

        Returns:
            Dict[str, Any]: K·∫øt qu·∫£ x·ª≠ l√Ω
        """

        results = {
            "processed_files": 0,
            "total_rows": 0,
            "skipped_files": 0,
            "errors": [],
            "file_details": [],
        }

        try:
            # Ensure destination folder exists
            os.makedirs(destination_folder, exist_ok=True)

            # Process each file in the data folder
            for file_name in os.listdir(data_folder):
                if not self._is_excel_file(file_name):
                    continue

                try:
                    # Check if file already imported
                    if self.is_file_imported(file_name):
                        print(f"{file_name} ƒë√£ ƒë∆∞·ª£c import tr∆∞·ªõc ƒë√≥, b·ªè qua.")
                        results["skipped_files"] += 1
                        continue

                    print(f"ƒêang x·ª≠ l√Ω: {file_name}")

                    # Process Excel file
                    file_path = os.path.join(data_folder, file_name)
                    df = self.process_excel_file(file_path, file_name)

                    if df.empty:
                        results["errors"].append(
                            f"Kh√¥ng c√≥ d·ªØ li·ªáu ƒë∆∞·ª£c tr√≠ch xu·∫•t t·ª´ file {file_name}"
                        )
                        continue

                    row_count = len(df)
                    print(f"ƒê√£ tr√≠ch xu·∫•t {row_count} d√≤ng t·ª´ file {file_name}")

                    # Save to database
                    self._save_to_database(df)

                    # Mark file as imported
                    self.mark_file_imported(file_name, "batch_excel", row_count)

                    # Move processed file to destination folder
                    shutil.move(file_path, os.path.join(destination_folder, file_name))

                    print(f"ƒê√£ import file: {file_name}")

                    results["processed_files"] += 1
                    results["total_rows"] += row_count
                    results["file_details"].append(
                        {"file_name": file_name, "rows": row_count}
                    )

                except Exception as e:
                    error_msg = f"L·ªói x·ª≠ l√Ω file {file_name}: {e}"
                    print(error_msg)
                    results["errors"].append(error_msg)

            # Commit all changes
            self.db.commit()

        except Exception as e:
            self.db.rollback()
            results["errors"].append(f"L·ªói batch import: {str(e)}")

        return results

    def _is_excel_file(self, file_name: str) -> bool:
        """
        Ki·ªÉm tra c√≥ ph·∫£i file Excel kh√¥ng

        Args:
            file_name (str): T√™n file Excel

        Returns:
            bool: True n·∫øu l√† file Excel, False n·∫øu kh√¥ng
        """

        excel_extensions = [".xlsx", ".xls"]
        return any(file_name.lower().endswith(ext) for ext in excel_extensions)

    def _save_to_database(self, df: pd.DataFrame):
        """
        L∆∞u DataFrame v√†o database s·ª≠ d·ª•ng bulk insert

        Args:
            df (pd.DataFrame): DataFrame c·∫ßn l∆∞u

        Returns:
            None
        """

        try:
            # Filter: ch·ªâ l∆∞u c√°c row c√≥ flightno v√† actype kh√¥ng null
            filtered_df = df[df["flightno"].notna() & df["actype"].notna()][
                [
                    "flightdate",
                    "flightno",
                    "route",
                    "actype",
                    "seat",
                    "adl",
                    "chd",
                    "cgo",
                    "mail",
                    "totalpax",
                    "source",
                    "acregno",
                    "sheet_name",
                ]
            ]

            # Convert DataFrame to SQL
            filtered_df.to_sql(
                "flight_raw",
                con=self.db.bind,
                if_exists="append",
                index=False,
                dtype={
                    "source": UnicodeText(),
                    "sheet_name": UnicodeText(),
                    "flightdate": UnicodeText(),
                },
            )

            # Log s·ªë l∆∞·ª£ng rows ƒë√£ l·ªçc
            original_count = len(df)
            filtered_count = len(filtered_df)
            if original_count > filtered_count:
                logging.info(
                    f"üìä ƒê√£ l·ªçc {original_count - filtered_count} rows thi·∫øu flightno/actype"
                )

        except Exception as e:
            logging.error(f"L·ªói l∆∞u v√†o database: {e}")
            raise e

    def run_data_cleaning_stored_procedure(self):
        """
        Ch·∫°y stored procedure ƒë·ªÉ l√†m s·∫°ch d·ªØ li·ªáu

        Returns:
            None
        """

        try:
            print("Ch·∫°y stored procedure l√†m s·∫°ch d·ªØ li·ªáu...")
            self.db.execute(text("EXEC usp_CleanAndProcessFlightData"))

            print("Ch·∫°y stored procedure log missing dimensions...")
            self.db.execute(text("EXEC usp_LogMissingDimensions"))

            self.db.commit()
            print("L√†m s·∫°ch d·ªØ li·ªáu ho√†n t·∫•t!")
        except Exception as e:
            self.db.rollback()
            logging.error(f"L·ªói ch·∫°y stored procedure l√†m s·∫°ch d·ªØ li·ªáu: {e}")
            raise e

    def run_missing_dimensions_import(self):
        """
        Ch·∫°y stored procedure ƒë·ªÉ import missing dimensions

        Returns:
            None
        """

        try:
            print("Ch·∫°y stored procedure import missing dimensions...")
            self.db.execute(text("EXEC usp_ImportAndUpdateMissingDimensions"))
            self.db.commit()
            print("Import missing dimensions ho√†n t·∫•t!")
        except Exception as e:
            self.db.rollback()
            logging.error(f"L·ªói ch·∫°y stored procedure import missing dimensions: {e}")
            raise e

    def get_processing_summary(self) -> Dict[str, Any]:
        """
        L·∫•y t√≥m t·∫Øt qu√° tr√¨nh x·ª≠ l√Ω d·ªØ li·ªáu theo schema th·ª±c t·∫ø (TO√ÄN B·ªò DATABASE)

        Returns:
            Dict[str, Any]: T√≥m t·∫Øt qu√° tr√¨nh x·ª≠ l√Ω d·ªØ li·ªáu
        """

        try:
            # Get total records in each table
            raw_count_result = self.db.execute(
                text("SELECT COUNT(*) FROM flight_raw")
            ).fetchone()

            processed_count_result = self.db.execute(
                text("SELECT COUNT(*) FROM flight_data_chot")
            ).fetchone()

            error_count_result = self.db.execute(
                text("SELECT COUNT(*) FROM error_table")
            ).fetchone()

            missing_actype_result = self.db.execute(
                text(
                    "SELECT COUNT(*) FROM Missing_Dimensions_Log WHERE Type = 'ACTYPE'"
                )
            ).fetchone()

            missing_route_result = self.db.execute(
                text("SELECT COUNT(*) FROM Missing_Dimensions_Log WHERE Type = 'ROUTE'")
            ).fetchone()

            # Get imported files count
            imported_files_result = self.db.execute(
                text("SELECT COUNT(*) FROM import_log")
            ).fetchone()

            return {
                "raw_records": raw_count_result[0] if raw_count_result else 0,
                "processed_records": (
                    processed_count_result[0] if processed_count_result else 0
                ),
                "error_records": error_count_result[0] if error_count_result else 0,
                "missing_actypes": (
                    missing_actype_result[0] if missing_actype_result else 0
                ),
                "missing_routes": (
                    missing_route_result[0] if missing_route_result else 0
                ),
                "imported_files": (
                    imported_files_result[0] if imported_files_result else 0
                ),
            }

        except Exception as e:
            logging.error(f"L·ªói l·∫•y t√≥m t·∫Øt qu√° tr√¨nh x·ª≠ l√Ω d·ªØ li·ªáu: {e}")
            return {
                "raw_records": 0,
                "processed_records": 0,
                "error_records": 0,
                "missing_actypes": 0,
                "missing_routes": 0,
                "imported_files": 0,
            }

    def get_current_session_summary(self, source_files: List[str]) -> Dict[str, Any]:
        """
        L·∫•y t√≥m t·∫Øt qu√° tr√¨nh x·ª≠ l√Ω CH·ªà CHO BATCH HI·ªÜN T·∫†I (filtered by source files)

        Args:
            source_files: Danh s√°ch t√™n files ƒë√£ x·ª≠ l√Ω trong session hi·ªán t·∫°i

        Returns:
            Dict[str, Any]: T√≥m t·∫Øt qu√° tr√¨nh x·ª≠ l√Ω c·ªßa batch hi·ªán t·∫°i
        """
        try:
            if not source_files:
                return {
                    "raw_records": 0,
                    "processed_records": 0,
                    "error_records": 0,
                    "missing_actypes": 0,
                    "missing_routes": 0,
                    "imported_files": 0,
                }

            # Build IN clause for SQL query
            files_placeholder = ", ".join(
                [f":file_{i}" for i in range(len(source_files))]
            )
            files_params = {f"file_{i}": file for i, file in enumerate(source_files)}

            # Get records count from flight_raw for current batch
            raw_count_result = self.db.execute(
                text(
                    f"SELECT COUNT(*) FROM flight_raw WHERE source IN ({files_placeholder})"
                ),
                files_params,
            ).fetchone()

            # Get records count from flight_data_chot for current batch
            processed_count_result = self.db.execute(
                text(
                    f"SELECT COUNT(*) FROM flight_data_chot WHERE source IN ({files_placeholder})"
                ),
                files_params,
            ).fetchone()

            # Get records count from error_table for current batch
            error_count_result = self.db.execute(
                text(
                    f"SELECT COUNT(*) FROM error_table WHERE source IN ({files_placeholder})"
                ),
                files_params,
            ).fetchone()

            # Get missing actypes from Missing_Dimensions_Log for current batch
            # Note: Missing_Dimensions_Log c√≥ th·ªÉ kh√¥ng c√≥ source column,
            # n√™n ta l·∫•y t·ª´ error_table c·ªßa batch hi·ªán t·∫°i
            missing_actype_result = self.db.execute(
                text(
                    f"""
                    SELECT COUNT(DISTINCT actype) 
                    FROM error_table 
                    WHERE source IN ({files_placeholder})
                    AND Is_InvalidActypeSeat = 1
                    AND actype IS NOT NULL
                """
                ),
                files_params,
            ).fetchone()

            # Get missing routes from error_table for current batch
            missing_route_result = self.db.execute(
                text(
                    f"""
                    SELECT COUNT(DISTINCT route) 
                    FROM error_table 
                    WHERE source IN ({files_placeholder})
                    AND Is_InvalidRoute = 1
                    AND route IS NOT NULL
                """
                ),
                files_params,
            ).fetchone()

            # Get imported files count for current batch
            imported_files_result = self.db.execute(
                text(
                    f"SELECT COUNT(*) FROM import_log WHERE file_name IN ({files_placeholder})"
                ),
                files_params,
            ).fetchone()

            return {
                "raw_records": raw_count_result[0] if raw_count_result else 0,
                "processed_records": (
                    processed_count_result[0] if processed_count_result else 0
                ),
                "error_records": error_count_result[0] if error_count_result else 0,
                "missing_actypes": (
                    missing_actype_result[0] if missing_actype_result else 0
                ),
                "missing_routes": (
                    missing_route_result[0] if missing_route_result else 0
                ),
                "imported_files": (
                    imported_files_result[0] if imported_files_result else 0
                ),
            }

        except Exception as e:
            logging.error(f"L·ªói l·∫•y t√≥m t·∫Øt batch hi·ªán t·∫°i: {e}")
            return {
                "raw_records": 0,
                "processed_records": 0,
                "error_records": 0,
                "missing_actypes": 0,
                "missing_routes": 0,
                "imported_files": 0,
            }
